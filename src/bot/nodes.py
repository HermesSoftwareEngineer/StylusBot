from langgraph.prebuilt.tool_node import ToolNode
from tools import tools, tools_de_cadastro_de_atendimento
from custom_types import State, prompt_atendente, RespostaNodeCadastrarAtendimento
from llms import llm
from pydantic import BaseModel, Field
from langchain_core.messages import SystemMessage

tools_node = ToolNode(tools)
tools_node_de_cadastro_de_atendimento = ToolNode(tools_de_cadastro_de_atendimento)
# tool_node_cadastrar_atendimento = ToolNode([cadastrar_atendimento])

def inicializar(state: State):
    if "atendimentoCadastrado" in state:
        print("EXISTE ATENDIMENTO CADASTRADO! veja: ", state['atendimentoCadastrado'])
        return state
    else:
        return {**state, "atendimentoCadastrado": False}

def cadastrar_atendimento(state: State):
    print("STATUS DO ATENDIMENTO CADASTRADO: ", state["atendimentoCadastrado"])
    if state["atendimentoCadastrado"] == False:
        system_message = SystemMessage(
            "VocÃª Ã© o StylusBot, atendente virtual da ImobiliÃ¡ria Stylus. Sempre se apresente antes de tudo."
            "Antes de responder Ã s dÃºvidas do cliente, solicite os seguintes dados de atendimento: nome, telefone e mÃ­dia de origem "
            "(a mÃ­dia corresponde ao canal pelo qual o cliente conheceu a imobiliÃ¡ria). "
            "ApÃ³s coletar todas as informaÃ§Ãµes, cadastre o atendimento. "
        )
    else:
        system_message = SystemMessage(
            """VocÃª Ã© o StylusBot, atendente virtual da ImobiliÃ¡ria Stylus. Sempre se apresente antes de tudo.
            Informe ao cliente que o atendimento foi cadastrado com sucesso e que agora ele pode fazer perguntas sobre imÃ³veis para alugar."""
        )

    conversation_messages = state["messages"]

    prompt = [system_message] + conversation_messages

    response = llm.bind_tools(tools_de_cadastro_de_atendimento).invoke(prompt)

    return {**state, "messages": response}

def consultar_ou_responder(state: State):
    prompt = prompt_atendente.invoke(state["messages"])
    response = llm.bind_tools(tools).invoke(prompt)
    # print(f"Resposta de consulta ou responder: ", response)
    return {**state, "messages": response}

def responder(state: State):
    """Gerando respostas com base nas ferramentas"""
    list_messages_tools = [m for m in reversed(state['messages']) if m.type == 'tool']
    docs_messages_tools = '\n\n'.join(m.content for m in reversed(list_messages_tools))

    system_message = SystemMessage(
        'SE TIVER IMÃ“VEIS NO BANCO DE DADOS (result), responda com:'
        '* ğŸ“ **EndereÃ§o:** [endereÃ§o do imÃ³vel]\n'
        '* ğŸ¡ **DescriÃ§Ã£o:** [descriÃ§Ã£o curta do imÃ³vel]\n'
        '* ğŸ’° **Valor:** [valor do aluguel + encargos]\n'
        '* ğŸ”— **Links de anÃºncio:** [se nÃ£o tiver links, oculte essa parte]\n\n'
        'SE NÃƒO TIVER IMÃ“VEIS NO BANCO DE DADOS (result), apenas diga que nÃ£o tem imÃ³veis com as caracterÃ­sticas, mas poderia tentar com outras caracterÃ­sticas. Seja gentil.'
        '\n\n' + docs_messages_tools
    )

    conversation_messages = [
        m for m in state['messages']
        if m.type in ('system', 'human')
        or (m.type == 'ia' and not m.tool_calls)
    ]
    
    prompt = [system_message] + conversation_messages

    return {**state, 'messages': llm.invoke(prompt)}