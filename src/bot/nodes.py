from .vector_stores import llm 
from langchain_core.messages import SystemMessage
from langgraph.graph import MessagesState
from .tools import tools, gerenciar_perfil_cliente
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

prompt_template = ChatPromptTemplate(
    [
        (
            "system",
            "Voc√™ √© um atendente da Imobili√°ria Stylus chamado 'StylusBot'. Responda da melhor maneira poss√≠vel. Utilize as ferramentas sempre que precisar. Se n√£o souber a resposta, basta dizer que n√£o sabe."
        ),
        (
            "system",
            "SEMPRE QUE O USU√ÅRIO PASSAR ALGUMA INFORMA√á√ÉO DO PERFIL DE IM√ìVEL PROCURADO, UTILIZE A FERRAMENTE DE BUSCAR IM√ìVEIS"
        ),
        MessagesPlaceholder(variable_name='messages')
    ]
)


def atualizar_perfil(state: MessagesState):
    """Atualiza o perfil do usu√°rio, se necess√°rio"""

    # Solicita ao LLM que gere um dicion√°rio com as novas informa√ß√µes do perfil
    system_message = SystemMessage("""
    Gere um dicion√°rio JSON com as seguintes informa√ß√µes para atualizar um perfil de usu√°rio:
    - id (int): Identificador do usu√°rio.
    - tipo_imovel (str): Tipo do im√≥vel, como 'casa' ou 'apartamento'.
    - localizacao (str): Bairro, cidade e estado.
    - valor_maximo (int): Valor m√°ximo que o usu√°rio deseja pagar.
    - quartos_banheiros (str): Exemplo: '2 quartos, 1 banheiro'.
    - modalidade (str): 'aluguel' ou 'compra'.
    - observacao (str): Observa√ß√£o adicional do usu√°rio.
    - nome (str): Nome completo do usu√°rio.
    - telefone (str): N√∫mero de telefone do usu√°rio.

    Responda apenas com um JSON v√°lido, sem explica√ß√µes. Adicione conte√∫do apenas nas informa√ß√µes que voc√™ tiver.
    """)

    prompt = [system_message] + state['messages']  # Adiciona a mensagem do sistema ao contexto

    response = llm.bind_tools([gerenciar_perfil_cliente], force=True).invoke(prompt)  # Chama o LLM para gerar os dados
    novas_informacoes = response.content  # Converte a resposta para um dicion√°rio

    return {'messages': novas_informacoes}

# ----------------------------------------------------------------------------

def consultar_ou_responder(state: MessagesState):
    """Usa o LLM para decidir se ferramentas devem ser consultadas"""
    
    tool_description = {
        "buscar_imoveis": "Busca im√≥veis dispon√≠veis para loca√ß√£o.",
        "perguntas_frequentes": "Responde a perguntas frequentes dos clientes.",
        "gerenciar_perfil_cliente": "Adiciona ou atualiza informa√ß√µes no perfil do cliente."
    }

    prompt = prompt_template.invoke(state['messages'])

    llm_with_tools = llm.bind_tools(
        tools=tools,
        tool_descriptions=tool_description
    )

    # Invoca o LLM para tomar a decis√£o
    llm_response = llm_with_tools.invoke(prompt)

    return {'messages': llm_response}

# ----------------------------------------------------------------------------

def preparar_consulta(state: MessagesState):
    """Preparar texto de consulta para ferramentas"""
    system_message = SystemMessage(
        """Leia bem a pergunta do usu√°rio e o contexto e em base disso elabore uma query para buscar informa√ß√µes nos documentos.
        Utilize sempre palavras chaves e relacionadas √† d√∫vida do usu√°rio, garantindo assertividade na utiliza√ß√£o das ferramentas."""
    )

    conversation_messages = [
        m for m in state['messages']
        if m.type in ('system', 'human')
        or (m.type == 'ia' and not m.tool_calls)
    ]

    prompt = [system_message] + conversation_messages
    llm_with_tools = llm.bind_tools(tools)

    return {'messages': llm_with_tools.invoke(prompt)}

def gerar_resposta(state: MessagesState):
    """Gerando respostas com base nas ferramentas"""
    list_messages_tools = [m for m in reversed(state['messages']) if m.type == 'tool']
    docs_messages_tools = '\n\n'.join(m.content for m in reversed(list_messages_tools))

    system_message = SystemMessage(
        'Voc√™ √© um assistente imobili√°rio. Sempre formate as respostas de im√≥veis da seguinte maneira:\n\n'
        '**üè† Informa√ß√µes do im√≥vel!**\n\n'
        '* üìç **Endere√ßo:** [endere√ßo do im√≥vel]\n'
        '* üè° **Descri√ß√£o:** [descri√ß√£o curta do im√≥vel]\n'
        '* üí∞ **Valor:** [valor do aluguel + encargos]\n'
        '* üîó **Links de an√∫ncio:** [links dispon√≠veis]\n\n'
        'Se n√£o encontrar im√≥veis, apenas diga "No momento, n√£o temos im√≥veis dispon√≠veis com essas caracter√≠sticas.'
        'Seja did√°tico, diga: Encontrei alguns im√≥veis similares ao que voc√™ procura, veja se lhe agrada...'
        'Seja sempre claro e gentil nas respostas, n√£o seja secos ou rudes."'
        '\n\n' + docs_messages_tools
    )

    conversation_messages = [
        m for m in state['messages']
        if m.type in ('system', 'human')
        or (m.type == 'ia' and not m.tool_calls)
    ]
    
    prompt = [system_message] + conversation_messages

    return {'messages': llm.invoke(prompt)}
